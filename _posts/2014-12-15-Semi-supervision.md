---
layout: post
title: "半监督学习综述"
description: ""
category: 
tags: []
---
{% include JB/setup %}

半监督学习是监督学习和非监督学习的混合体，训练数据包括标注数据和非标注数据。根据学习目标分为两类：一类是监督学习任务，得到输入—输出的映射函数，利用未标注数据进行函数的优化；另一类是非监督学习任务，得到聚类的结果，利用标注数据提高效果。

##监督学习任务

首先利用标注数据获得一个函数，然后利用未标注数据进行优化。包括自学习方法、互学习方法、基于图的方法、基于生成模型的方法、转导支持向量机等。

###自学习

训练得到函数后，对未标注数据进行自动标注，同时给出可靠度，只有可靠度较高的自动标注结果才被用于函数的再学习，直到学习结果不变或者达到合适的迭代次数。基于生成模型的方法和转导支持向量机都是这种思路。

###互学习

利用不同信息间的互补性达到相互学习的目的。用不同的已标注的训练集分别训练得到不同的函数，都对未标注数据进行自动标注，同时给出可靠度，只有可靠度较高的自动标注结果才被用于函数的再学习，再学习时的训练集来自其他关联信息对应的函数。直到学习结果不变或者达到合适的迭代次数，输出训练得到的多个分类器。

###基于图的方法

图的节点表示数据，边反映了数据间的相似度。计算未标注数据和标注数据的关联程度，来确定未标注数据的标注结果。这里的关联程度分为硬关联和软关联，对于硬关联用最小割方法，对于软关联用谐函数方法。

####最小割方法

最小割试图找到一个合适的割集，使得权值最小。

Step1 构造图，权值可以为距离的反比；

Step2 增加两个特殊节点：源点和汇点，表示两个类，分别与各自的标注数据相连，权值无穷大，表示必须在一起；

Step3 用图论的最大流（最小割）算法求解；

Step4 根据分割结果确定未标注数据的标注结果。

####谐函数方法

可以从随机游走和电路网络的角度认识。从随机游走的角度，节点的边的权值视为两个彼此行走的概率，概率与相似度成正比。未标注节点与某一类别直接的关联程度可以看成是：从未标注节点出发，按照边上的概率行走，直到走到第一个被标注为相应类别的节点概率。计算出该未标注点到每个类别的行走概率后，按概率最大原则进行标注。从电路网路的角度，一类为正极，另一类为负极，施加电压，根据电压值的大小确定标注结果。

###基于生成模型的方法

####高斯混合模型方法

执行步骤：

Step1 监督学习阶段，每个类别（高斯成分），给了一定量的数据。可以直接算出相应的高斯成分的参数；

Step2 是非监督学习阶段E步，计算对于每个未标注数据，分别确定到各个高斯成分的概率；

Step3 非监督学习阶段的M步，组合标注和未标注数据的期望，使其最大化，直接解析式赋值迭代；

Step4 反复执行Step2-Step3，直到结果稳定或达到最大迭代次数。

####朴素贝叶斯混合模型方法

执行步骤：

Step1 监督学习阶段，用m-估计法得到概率密度函数；

Step2 非监督学习阶段E步，利用已有的朴素贝叶斯混合模型，对每个未标注数据计算到各个类别的概率；

Step3 非监督学习阶段M步，依据MLE准则，使期望最大化；

Step4 反复执行Step2-Step3，直到结果稳定或达到最大迭代次数。

###转导支持向量机

转导SVM的优化结果既要使两类数据的间隔最大化，又要使未标注数据的标注结果最优化。S3VM，是一个两层循环算法，内层是原始SVM学习过程，外层是对未标注数据的自动标注结果的学习过程。外循环的目标是在所有可能标注结果中找到最优，S3VM通过贪婪的局部搜索来解决这一问题。

执行步骤：

Step1 利用已学习的SVM计算每个未标注数据的分类结果，在被分类为正样本的数据中可靠度（数据到分类超平面的距离）最高的若干个为正样本，其余全部作为反样本；

Step2 进行标注后，再次用SVM进行学习，得到新的结果；

Step3 对未标注的标注结果进行两两交换，某一正样本改为反样本，某一反样本改为正样本，再次执行SVM学习，看能否提高学习效果，能够提高进行交换，否则不交换；

Step4 重复Step3，直到满足停止条件。

##非监督学习任务

1.基于部分标注的k-均值算法

对k-均值聚类算法进行改进，初始值为已标注数据，种子点的归属可以保持不变，或者发生变化。

2.基于两两约束的k-均值算法

在每次确定数据归属到某一个簇时，确定结果不应该破坏给定的约束，即“must-link”所对应的两个数据被划分到一个簇里，而“cannot-link”必须不划分到一个簇里。在分配时，分配给距离最近且不破坏约束条件的簇。如果不存在，则算法失败。

3.基于两两约束的层次聚类方法

对于层次聚类来说，“must-link”的距离为0，“cannot-link”距离为最大距离。